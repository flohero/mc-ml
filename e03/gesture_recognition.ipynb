{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Gesture Recognition\n",
    "\n",
    "### Dataset\n",
    "* The dataset contains different arm gestures from different participants.\n",
    "    * Recording device and wearing position: smartwatch (LG Watch G)running Android Wear, worn at right wrist.\n",
    "    * Recorded data: 3 axes acceleration measured in G [9.81m/s^2], with a target sampling rate of 50Hz.\n",
    "    * Gestures, participants and samples: 8 gestures, 9 participants. Each participant performed each gesture 30 times, which results in a total of 240 samples per participants, 270 samples per gesture and 2160 samples in total in the data set.\n",
    "    * The publication describing the dataset in more detail can be found here:https://ambientintelligence.aalto.fi/team_old/findling/pdfs/publications/Kefer_16_ComparingPlacementTwo.pdf\n",
    "* Provided csv files:\n",
    "    * Acceleration recordings are split per axis into separate csv files (one file per axis). This implies that e.g. the Nth line of each file belong to the same gesture, participant and sample and represent the according x, y and z axis acceleration recordings.\n",
    "    * Csv file columns are in this order:\n",
    "        1. gesture\n",
    "        2. participantNr\n",
    "        3. sampleNr\n",
    "      4. N acceleration values (different lengths per sample)\n",
    "\n",
    "\n",
    "### Task\n",
    "\n",
    "Goal is to build (a) successful gesture recognition model(s). The modelshould learn to distinguish between N gesture acceleration recording, then be able to decide for new recordings which gesture it shows. Load data, preprocess it, and extract features (see hints below).\n",
    "* Do a gallery dependent data partitioning and train models using cross validation. Compare different models and feature extraction approaches by their cross validation results, and for the selected “best”model show at least the confusion matrix for heldback test partition over different gestures. Discuss what the best feature extrac-tion/model configuration is you found, and if there are gestures that are harder to distinguish than others.\n",
    "* *Bonus objective:* do gallery independent data partitioning instead using leave subject out cross validation (LSOCV, see slides)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
